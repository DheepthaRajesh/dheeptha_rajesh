{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29f4ddd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/ES/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# opening the datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ES:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file_path_ES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/ES/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path_ES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_ES:\n\u001b[1;32m      8\u001b[0m     read_line_ES \u001b[38;5;241m=\u001b[39m file_ES\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/ES/train'"
     ]
    }
   ],
   "source": [
    "# opening the datasets\n",
    "\n",
    "# ES:\n",
    "\n",
    "file_path_ES = r\"Data/ES/train\"\n",
    "\n",
    "with open(file_path_ES, \"r\") as file_ES:\n",
    "    read_line_ES = file_ES.readlines()\n",
    "    \n",
    "    \n",
    "# print(read_line_ES)\n",
    "# print(len(read_line_ES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a62fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RU:\n",
    "\n",
    "file_path_RU = r\"Data/RU/train\"\n",
    "\n",
    "with open(file_path_RU, \"r\") as file_RU:\n",
    "    read_line_RU = file_RU.readlines()\n",
    "    \n",
    "# print(read_line_RU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032f9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files to get the word and labels & adding START and STOP special states\n",
    "\n",
    "# ES:\n",
    "\n",
    "# list with tuples containing word and label -> ('word', 'label')\n",
    "\n",
    "# START -> ('', 'START')\n",
    "\n",
    "# STOP -> ('', 'STOP')\n",
    "\n",
    "train_data_ES = []\n",
    "\n",
    "# add the START state for the first sentence\n",
    "train_data_ES.append((\"\", \"START\"))\n",
    "\n",
    "for line in read_line_ES:\n",
    "    if line!=\"\\n\":   #not empty line\n",
    "        \n",
    "        word, label = line.strip().split()\n",
    "        \n",
    "        train_data_ES.append((word, label))\n",
    "        \n",
    "    else:  #add the STOP state to denote END of sentence and add the START state for the start of the next sentence\n",
    "        train_data_ES.append((\"\", \"STOP\"))\n",
    "        train_data_ES.append((\"\", \"START\"))\n",
    "        \n",
    "# print(train_data_ES)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# RU :\n",
    "\n",
    "# list with tuples containing word and label -> ('word', 'label')\n",
    "\n",
    "# START -> ('', 'START')\n",
    "\n",
    "# STOP -> ('', 'STOP')\n",
    "\n",
    "train_data_RU = []\n",
    "\n",
    "# add the START state for the first sentence\n",
    "train_data_RU.append((\"\", \"START\"))\n",
    "\n",
    "for line in read_line_RU:\n",
    "    if len(line.strip().split(\" \")) == 2: #line contains both word and label\n",
    "        word, label = line.strip().split(\" \")\n",
    "        \n",
    "        train_data_RU.append((word, label))\n",
    "        \n",
    "    else:  #add the STOP state to denote END of sentence and add the START state for the start of the next sentence\n",
    "        train_data_RU.append((\"\", \"STOP\"))\n",
    "        train_data_RU.append((\"\", \"START\"))\n",
    "        \n",
    "# print(train_data_RU)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f7295",
   "metadata": {},
   "source": [
    "## Transition Parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8a5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dictionary containing count of each label (initialised to zero):\n",
    "\n",
    "label_count = {\"START\":0, \"B-positive\":0, \"I-positive\":0, \"O\":0, \"B-negative\":0, \"I-negative\":0, \"B-neutral\":0, \"I-neutral\":0, \"STOP\":0}\n",
    "\n",
    "\n",
    "\n",
    "# dictionary storing the state transitions and its respective count:\n",
    "\n",
    "# eg: {(START, B-positive):1, (B-neutral, I-neutral):3}\n",
    "\n",
    "label_transitions={}\n",
    "\n",
    "def estimate_transition_parameters(data):\n",
    "    \n",
    "    # dictionary storing the state transitions and its respective transition probability:\n",
    "    \n",
    "    transition_probability = {}\n",
    "    \n",
    "    prev_state = data[0][1] # initally the START state\n",
    "    \n",
    "    for elem in data[1:]: # Exclude the first element because we have already considered the START state\n",
    "        \n",
    "        current_state = elem[1]\n",
    "        \n",
    "        label_count[prev_state]+=1 # increment count of prev state\n",
    "        \n",
    "        # if the transition does not exist, initialise to zero:\n",
    "        if (prev_state, current_state) not in label_transitions:\n",
    "            label_transitions[(prev_state, current_state)] = 0\n",
    "            \n",
    "        # and then increment the count of transition from prev to current:\n",
    "        label_transitions[(prev_state, current_state)] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Following the convention given in the question\n",
    "        \n",
    "        # Using the transition probability formula:\n",
    "        transition_probability[(current_state, prev_state)] = label_transitions[(prev_state, current_state)] / label_count[prev_state]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # To get rid of the transition from END to START = 1.0, we can remove it from the transition_probability dictionary:\n",
    "        if current_state==\"START\" and prev_state==\"END\":\n",
    "            transition_probability.pop((current_state, prev_state))\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Move to the next state with the prev state as the now current state:\n",
    "        \n",
    "        prev_state = current_state\n",
    "\n",
    "#     print(\"label count\",label_count)\n",
    "        \n",
    "    return transition_probability\n",
    "        \n",
    "        \n",
    "# For ES:  \n",
    "    \n",
    "transition_parameters_ES= estimate_transition_parameters(train_data_ES)\n",
    "\n",
    "# print(\"Transition Parameters for ES:\")\n",
    "# print(transition_parameters_ES)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# For RU:  \n",
    "    \n",
    "transition_parameters_RU= estimate_transition_parameters(train_data_RU)\n",
    "\n",
    "# print(\"Transition Parameters for RU:\")\n",
    "# print(transition_parameters_RU)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# e.g. transition_probability = {('O', 'START'): 0.9289176090468497} \n",
    "\n",
    "# where the transition probability of state START to state O is 0.929"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444bb25",
   "metadata": {},
   "source": [
    "## Emission Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05722d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Files and Load\n",
    "def readFile(filePath: str):\n",
    "    with open(filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.readlines()\n",
    "    \n",
    "def loadFile(file: list):\n",
    "    return [word.strip() for word in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09e7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain total word count for each word\n",
    "def WordCount(file: list):\n",
    "    x = {\n",
    "        \"O\": 0,\n",
    "        \"B-positive\": 0,\n",
    "        \"B-negative\": 0,\n",
    "        \"B-neutral\": 0,\n",
    "        \"I-positive\": 0,\n",
    "        \"I-negative\": 0,\n",
    "        \"I-neutral\": 0\n",
    "    }\n",
    "    for i in range(len(file)):\n",
    "        if file[i] != \"\":\n",
    "            l = file[i].split()\n",
    "            entity = l[0]\n",
    "            label = l[1]\n",
    "            key = f\"{entity}_{label}\"\n",
    "            if key in x:\n",
    "                x[key] += 1\n",
    "                x[label] += 1\n",
    "            else:\n",
    "                x[key] = 1\n",
    "                x[label] += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb1ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate emission values\n",
    "def calculate_emission(input_x: dict, k=1):\n",
    "    emissionResult = 1\n",
    "    output_x = {}\n",
    "    label_l = [\"O\", \"B-positive\", \"B-negative\", \"B-neutral\", \"I-positive\", \"I-negative\", \"I-neutral\"]\n",
    "    total_labels = sum(input_x[label] for label in label_l)\n",
    "\n",
    "    for key, value in input_x.items():\n",
    "        if key not in label_l:\n",
    "            word, label = key.split(\"_\")\n",
    "            count_y = input_x[label]\n",
    "            count_unk_y = input_x.get(f\"#UNK#{label}\", 0)\n",
    "            # Using provided formula, calculate emission probability of word x with tag y\n",
    "            em_value = (value + k) / (count_y + k * (total_labels + 1))\n",
    "            output_x[key] = em_value\n",
    "            emissionResult *= em_value\n",
    "\n",
    "    # Add emission probability for #UNK# token for each label\n",
    "    for label in label_l:\n",
    "        count_y = input_x[label]\n",
    "        count_unk_y = input_x.get(f\"#UNK#{label}\", 0)\n",
    "        em_value = k / (count_y + k * (total_labels + 1))\n",
    "        output_x[f\"#UNK#{label}\"] = em_value\n",
    "\n",
    "    return emissionResult, output_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29354b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Sentiment Prediction\n",
    "def predSentiment(input_sentence, emission_params):\n",
    "    predicted_tags = []\n",
    "    for word in input_sentence:\n",
    "        max_prob = 0\n",
    "        max_tag = \"O\"\n",
    "        for tag, prob in emission_params.items():\n",
    "            if tag.startswith(word):\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_tag = tag\n",
    "        predicted_tags.append(max_tag)\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0caf3704",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/ES/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m devOutFilePath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/ES/dev.out\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Read and load file paths\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m trainFile \u001b[38;5;241m=\u001b[39m \u001b[43mreadFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainFilePath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loadTrainFile \u001b[38;5;241m=\u001b[39m loadFile(trainFile)\n\u001b[1;32m     10\u001b[0m testFile \u001b[38;5;241m=\u001b[39m loadTrainFile\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mreadFile\u001b[0;34m(filePath)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadFile\u001b[39m(filePath: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/ES/train'"
     ]
    }
   ],
   "source": [
    "#Define file paths to use\n",
    "trainFilePath = \"Data/ES/train\"\n",
    "devInFilePath = \"Data/ES/dev.in\"\n",
    "devOutFilePath = \"Data/ES/dev.out\"\n",
    "\n",
    "#Read and load file paths\n",
    "trainFile = readFile(trainFilePath)\n",
    "loadTrainFile = loadFile(trainFile)\n",
    "\n",
    "testFile = loadTrainFile\n",
    "\n",
    "x = WordCount(testFile)\n",
    "# print(x)\n",
    "emissionResult, emissionParams = calculate_emission(x)\n",
    "# print(f\"Labels : corresponding emission value: \\n{emissionParams}\")\n",
    "\n",
    "# Read development set data\n",
    "devInFile = readFile(devInFilePath)\n",
    "processedDevInFile = loadFile(devInFile)\n",
    "\n",
    "# Predict sentiments for the development set\n",
    "sentiment_prediction = [predSentiment(sentence.split(), emissionParams) for sentence in processedDevInFile]\n",
    "\n",
    "# Write the predictions to dev.p1.out\n",
    "with open(devOutFilePath, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence_tags in sentiment_prediction:\n",
    "        f.write(\"\\n\".join(sentence_tags) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b8fc0",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4d1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8015c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal output:  ['', 'O', 'O', 'O', 'O', 'O', 'O', 'B-positive', '']\n",
      "k output:  [['O', 'B-positive', 'B-negative', 'B-neutral', 'I-positive'], ['O', 'B-positive', 'B-negative', 'B-neutral', 'I-positive'], ['O', 'B-positive', 'B-negative', 'B-neutral', 'I-positive'], ['O', 'B-positive', 'B-negative', 'B-neutral', 'I-positive'], ['O', 'B-positive', 'B-negative', 'B-neutral', 'I-positive'], ['O', 'B-positive', 'I-positive', 'B-negative', 'I-negative'], ['I-neutral']]\n"
     ]
    }
   ],
   "source": [
    "def viterbi_best_k(emission_probability, transition_probability, data, k):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    states = list(state for state in label_count.keys() if state!=\"START\" and state!=\"STOP\")\n",
    "    \n",
    "    states_with_START = list(state for state in label_count.keys() if state!=\"STOP\")\n",
    "    \n",
    "    all_states = list(state for state in label_count.keys())\n",
    "    \n",
    "#     print(states)\n",
    "    \n",
    "    # 2D array pi to store the score\n",
    "    \n",
    "    # START - 0 STOP - 8\n",
    "    \n",
    "    pi=[[0 for i in range(len(all_states))] for j in range(len(all_states))]\n",
    "    \n",
    "#     print(pi)\n",
    "\n",
    "#     Output sequence array:\n",
    "\n",
    "    output = [\"\" for i in range(k)]\n",
    "    \n",
    "#     print(pi.shape)\n",
    "#     print(pi)\n",
    "    \n",
    "    # 1. Initialisation:\n",
    "    \n",
    "    pi[0][0] = 1\n",
    "\n",
    "    \n",
    "#     print(pi)\n",
    "    \n",
    "    # 2. FOR LOOP:\n",
    "    \n",
    "    for j in range(0, len(states)-1):\n",
    "        \n",
    "        for u in states:\n",
    "            \n",
    "            max_score = float('-inf')\n",
    "            \n",
    "            for v in states_with_START:\n",
    "                \n",
    "#                 print(\"u\",u)\n",
    "#                 print(\"v\",v)\n",
    "\n",
    "    #             print(f\"{data[j+1][0]}_{states[u]}\")\n",
    "\n",
    "                if f\"{data[j+1][0]}_{u}\" not in emission_probability:\n",
    "                    emission_probability[f\"{data[j+1][0]}_{u}\"] = 0\n",
    "\n",
    "                emission = emission_probability[f\"{data[j+1][0]}_{u}\"]\n",
    "    #             print(\"j\", j)\n",
    "    #             print(\"u\",u)\n",
    "#                 print(\"emission\",emission)\n",
    "\n",
    "\n",
    "                if (u,v) not in transition_probability:\n",
    "                    transition_probability[(u,v)] = 0\n",
    "            \n",
    "                transition = transition_probability[(u,v)]\n",
    "#                 print(transition)\n",
    "\n",
    "                score = pi[j][all_states.index(v)] * emission * transition\n",
    "                max_score = max(max_score, score)\n",
    "                \n",
    "            pi[j+1][all_states.index(u)] = max_score\n",
    "#             print(pi)\n",
    "            \n",
    "    # 3. Final Step:\n",
    "    \n",
    "    \n",
    "        \n",
    "    max_score = float('-inf')\n",
    "\n",
    "    for v in states_with_START:\n",
    "\n",
    "        if (\"STOP\",v) not in transition_probability:\n",
    "                transition_probability[(\"STOP\",v)] = 0\n",
    "\n",
    "        transition = transition_probability[(\"STOP\",v)]\n",
    "\n",
    "        score = pi[len(states)][all_states.index(v)] * transition\n",
    "        max_score = max(max_score, score)\n",
    "    \n",
    "    pi[len(states)+1][all_states.index(\"STOP\")] = max_score\n",
    "    \n",
    "    \n",
    "    # Backtracking:\n",
    "    \n",
    "    # Step 1:\n",
    "    \n",
    "    output = [\"\" for i in range(len(all_states))]\n",
    "    k_output = [[] for i in range(len(states))]\n",
    "    \n",
    "    max_score = float('-inf')\n",
    "    \n",
    "    for u in states:\n",
    "        \n",
    "        if (\"STOP\", u) not in transition_probability:\n",
    "            transition_probability[(\"STOP\", u)] = 0\n",
    "        transition = transition_probability[(\"STOP\", u)]\n",
    "        \n",
    "        score = pi[len(states)][all_states.index(u)] * transition\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            \n",
    "            output[len(states)] = u\n",
    "            \n",
    "    k_output[len(states)-1] = [u]\n",
    "            \n",
    "    #Step 2:\n",
    "    \n",
    "    for j in range(len(states)-1, 0, -1):\n",
    "        \n",
    "        max_score = float('-inf')\n",
    "        \n",
    "        for u in states:\n",
    "            \n",
    "            for v in states_with_START:\n",
    "                \n",
    "                if (output[j+1],u) not in transition_probability:\n",
    "                    transition_probability[(output[j+1],u)] = 0\n",
    "            \n",
    "                transition = transition_probability[(output[j+1],u)]\n",
    "                \n",
    "                score = pi[j][all_states.index(u)] * transition\n",
    "                \n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_state_j = u\n",
    "                    \n",
    "        output[j] = best_state_j\n",
    "        \n",
    "    for j in range(len(states) - 1, 0, -1):\n",
    "        \n",
    "        k_output[j-1] = top_k_states(j, pi, transition_probability, k, output)\n",
    "    \n",
    "    print(\"normal output: \",output)\n",
    "    \n",
    "    print(\"k output: \",k_output)\n",
    "    \n",
    "    \n",
    "def top_k_states(j, pi, transition_probability, k, output):\n",
    "    # Create a list to store (state, score) tuples\n",
    "    state_scores = []\n",
    "    \n",
    "    states = list(state for state in label_count.keys() if state!=\"START\" and state!=\"STOP\")\n",
    "    \n",
    "    states_with_START = list(state for state in label_count.keys() if state!=\"STOP\")\n",
    "    \n",
    "    all_states = list(state for state in label_count.keys())\n",
    "    \n",
    "    for u in states:\n",
    "        max_score = float('-inf')\n",
    "        max_state = None\n",
    "        \n",
    "        for v in states_with_START:\n",
    "            if (output[j + 1], u) not in transition_probability:\n",
    "                transition_probability[(output[j + 1], u)] = 0\n",
    "            transition = transition_probability[(output[j + 1], u)]\n",
    "            score = pi[j][all_states.index(v)] * transition\n",
    "            \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_state = v\n",
    "        \n",
    "        state_scores.append((u, max_score, max_state))\n",
    "    \n",
    "    # Sort the state_scores by score in descending order\n",
    "    state_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top-k states\n",
    "    return [state for state, _, _ in state_scores[:k]]\n",
    "\n",
    "    \n",
    "    \n",
    "viterbi_best_k(emissionParams, transition_parameters_ES, train_data_ES, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c191b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
